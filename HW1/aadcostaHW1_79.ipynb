{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Netid : aadcosta\n",
    "#SUID : 594303899\n",
    "#Pin No : 79\n",
    "\n",
    "# Class function called Func is the utility functions containing the logic for different approaches and the installation of the required libraries for the same are done below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fancyimpute in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: pytest in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fancyimpute) (7.4.2)\n",
      "Requirement already satisfied: nose in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fancyimpute) (1.3.7)\n",
      "Requirement already satisfied: knnimpute>=0.1.0 in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fancyimpute) (0.1.0)\n",
      "Requirement already satisfied: cvxopt in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fancyimpute) (1.3.2)\n",
      "Requirement already satisfied: cvxpy in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fancyimpute) (1.3.2)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fancyimpute) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.10 in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from knnimpute>=0.1.0->fancyimpute) (1.22.3)\n",
      "Requirement already satisfied: six in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=0.24.2->fancyimpute) (3.2.0)\n",
      "Requirement already satisfied: scs>=1.1.6 in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cvxpy->fancyimpute) (3.2.3)\n",
      "Requirement already satisfied: ecos>=2 in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cvxpy->fancyimpute) (2.0.12)\n",
      "Requirement already satisfied: osqp>=0.4.1 in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cvxpy->fancyimpute) (0.6.3)\n",
      "Requirement already satisfied: setuptools>65.5.1 in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cvxpy->fancyimpute) (68.2.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytest->fancyimpute) (1.1.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytest->fancyimpute) (21.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytest->fancyimpute) (0.4.4)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytest->fancyimpute) (1.3.0)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytest->fancyimpute) (2.0.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pytest->fancyimpute) (2.0.1)\n",
      "Requirement already satisfied: qdldl in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from osqp>=0.4.1->cvxpy->fancyimpute) (0.1.7.post0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\arlene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging->pytest->fancyimpute) (3.0.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Arlene\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install fancyimpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "from fancyimpute import IterativeImputer\n",
    "import sys,os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below class Func contains the functions for all different algorithms such as Mean,Median, Local Gradient, Nearest Neighbour(Both distance between data points using difference and Euclidean distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Func:\n",
    "\n",
    "    def format_to_two_decimal_places(self,value):\n",
    "        return '{:.2f}'.format(value)\n",
    "\n",
    "\n",
    "    def get_df(self,path):\n",
    "        data_df = pd.read_csv(rf'{path}')\n",
    "        selected_columns_df = data_df[['2017', '2018', '2019', '2020', '2021', '2022']]\n",
    "        return selected_columns_df\n",
    "\n",
    "    def get_nan_value(self,originaldf):\n",
    "        nanno = []\n",
    "\n",
    "        for i in range(originaldf.shape[0]):\n",
    "            for j in range(originaldf.shape[1]):\n",
    "                if np.isnan(originaldf.iloc[i, j]):\n",
    "                    nanno.append([i, j])\n",
    "        return nanno\n",
    "\n",
    "    def get_nan_value_field(self,originaldf):\n",
    "        '''Function for computing the index of the NaN values in the original dataframe for computing avg absolute Error'''\n",
    "        nanno = []\n",
    "\n",
    "        for j in range(originaldf.shape[1]):\n",
    "            for i in range(originaldf.shape[0]):\n",
    "                if np.isnan(originaldf.iloc[i, j]):\n",
    "                    nanno.append([i, j])\n",
    "        print(nanno)\n",
    "        return nanno\n",
    "\n",
    "    \n",
    "    def get_value(self,nanarray,df):\n",
    "        '''Get NaN valued elements within dataframe for computing absolute Error between original and missing value dataframe '''\n",
    "        arrval = []\n",
    "        for val in nanarray:\n",
    "            arrval.append(df.iloc[val[0], val[1]])\n",
    "        return arrval\n",
    "\n",
    "    def get_absolute_error(self,actual_values,imputed_values):\n",
    "        '''Function for computing avg absolute Error'''\n",
    "        absolute_errors = []\n",
    "        for i in range(0,len(actual_values)):\n",
    "            absolute_errors.append(abs(actual_values[i] - imputed_values[i]))\n",
    "\n",
    "\n",
    "        # Calculate the average absolute error\n",
    "        average_absolute_error = sum(absolute_errors)//len(absolute_errors)\n",
    "\n",
    "        return average_absolute_error\n",
    "\n",
    "    def replace_nan_with_mean(self,row):\n",
    "        '''Function for computing mean for non-nan valued locations[Can be either row-wise or col wise based on axis]'''\n",
    "        mean = row.mean(skipna=True)  # Calculate row mean excluding NaN values\n",
    "        return row.fillna(mean)  # Replace NaN with the mean\n",
    "\n",
    "    def replace_nan_with_median(self,row):\n",
    "        '''Function for computing median for non-nan valued locations[Can be either row-wise or col wise based on axis]'''\n",
    "        median = row.median(skipna=True)  # Calculate row mean excluding NaN values\n",
    "        return row.fillna(median)  # Replace NaN with the mean\n",
    "\n",
    "\n",
    "    def get_local_gradient(self,df):\n",
    "        '''Function for capturing the gradient based on nearest values'''\n",
    "        for i in range(df.shape[0]):\n",
    "            for j in range(df.shape[1]):\n",
    "                if np.isnan(df.iloc[i, j]):\n",
    "                    if j == 0:\n",
    "                        df.iloc[i, j] = 2 * df.iloc[i, 1] - df.iloc[i, 2]\n",
    "                    elif j == 5:\n",
    "                        df.iloc[i, j] = 2 * df.iloc[i, 4] - df.iloc[i, 3]\n",
    "                    else:\n",
    "\n",
    "                        preceding_year = j - 1\n",
    "                        following_year = j + 1\n",
    "\n",
    "                        df.iloc[i, j] = (df.iloc[i, preceding_year] + df.iloc[i, following_year]) / 2\n",
    "        return df\n",
    "\n",
    "\n",
    "    # Define the L1 distance function\n",
    "    def l1_distance(self,row1, row2):\n",
    "        '''Formula for capturing distances between two rows excluding the NaN indexes'''\n",
    "        common_fields = set(row1.dropna().index) & set(row2.dropna().index)\n",
    "        distance = 0\n",
    "        count = 0\n",
    "\n",
    "        for field in common_fields:\n",
    "            distance += abs(row1[field] - row2[field])\n",
    "            count += 1\n",
    "\n",
    "        return distance / count if count > 0 else float('inf')\n",
    "\n",
    "        # Define the L2 distance function : Average Squared differences\n",
    "    def l2_distance(self, row1, row2):\n",
    "        '''Formula for capturing distance between two rows based on Euclidean distance'''\n",
    "        common_fields = set(row1.dropna().index) & set(row2.dropna().index)\n",
    "        distance = 0\n",
    "        count = 0\n",
    "\n",
    "        for field in common_fields:\n",
    "            distance += (row1[field] - row2[field])**2\n",
    "            count += 1\n",
    "\n",
    "        return distance / count if count > 0 else float('inf')\n",
    "\n",
    "    def get_nn(self,df,type):\n",
    "        '''Function for computing nn algo by excluding rows having same NaN indexes'''\n",
    "        dfres = df.copy(deep=True)\n",
    "        for i, row1 in df.iterrows():\n",
    "            min_distance = float('inf')  # Initialize the minimum distance to infinity\n",
    "            nearest_neighbor = None  # Initialize the nearest neighbor\n",
    "\n",
    "            for j, row2 in df.iterrows():\n",
    "                if i != j:  # Exclude the current faculty member\n",
    "                    # Check if the current faculty member has missing values in the same field as the neighbor\n",
    "                    missing_fields_i = set(row1.index[row1.isna()])\n",
    "                    missing_fields_j = set(row2.index[row2.isna()])\n",
    "                    if not missing_fields_i & missing_fields_j:\n",
    "                        if type == 'l1':\n",
    "                            distance = self.l1_distance(row1, row2)\n",
    "                        elif type == 'l2':\n",
    "                            distance = self.l2_distance(row1, row2)\n",
    "                        if distance < min_distance:\n",
    "                            #print(type,distance,i,j)\n",
    "                            min_distance = distance\n",
    "                            nearest_neighbor = row2\n",
    "\n",
    "            # Replace missing values in the current faculty member with values from the nearest neighbor\n",
    "            if nearest_neighbor is not None:\n",
    "                for field in row1.index[row1.isna()]:\n",
    "                    dfres.at[i, field] = nearest_neighbor[field]\n",
    "        return dfres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1 : General Imputation Algorithm( I have used Mice based on FancyImpute [Library available in Python])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path = 'E:\\MS\\MS_studies\\Sem_2\\IntrotoML\\HW0\\Missouri.csv'\n",
    "missing_path = 'E:\\MS\\MS_studies\\Sem_2\\IntrotoML\\HW0\\missingNoisyMissouri.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df:\n",
      "   2017  2018  2019  2020  2021  2022\n",
      "0    13     5     8     8    12     9\n",
      "1  2293  2249  2193  2218  2152  2094\n",
      "2     4     2     3     7     4     3\n",
      "3   336   360   337   321   298   289\n",
      "4   313   309   256   310   306   279\n",
      "5    39    48    33    36    43    38\n",
      "6    14    20    23    69   114   107\n",
      "7    23    44   150   182   255   268\n",
      "8    34    44    60    59    38    67\n",
      "9    28    34    34    16    33    33\n",
      "Missing df imputed with Mice is:\n",
      "            0            1            2            3            4            5\n",
      "0    15.00000    25.188646     2.000000     3.000000    18.000000     4.000000\n",
      "1  2298.00000  2239.000000  2054.436211  2208.000000  2154.000000  2098.000000\n",
      "2     9.00000    18.644771     1.000000    10.000000     2.000000    13.000000\n",
      "3   338.00000   360.000000   337.000000   307.680052   298.000000   289.000000\n",
      "4   323.00000   314.000000   250.000000   305.000000   302.000000   293.045661\n",
      "5    40.00000    43.000000    37.000000    34.776230    44.000000    39.000000\n",
      "6    15.00000    22.000000    28.000000    70.000000   102.457828   114.000000\n",
      "7    53.73127    35.000000   142.000000   189.000000   252.000000   266.000000\n",
      "8    32.00000    40.000000    64.000000    40.594148    34.000000    60.000000\n",
      "9    20.00000    31.913226    35.000000    17.000000    30.000000    32.000000\n",
      "Average Absolute Error using Mice is 26.0\n"
     ]
    }
   ],
   "source": [
    "f = Func()\n",
    "originaldf = f.get_df(rf'{original_path}')\n",
    "print(\"Original df:\")\n",
    "print(originaldf)\n",
    "\n",
    "# Step 2: Capture Missing CSV\n",
    "missingdf = f.get_df(rf'{missing_path}')\n",
    "\n",
    "# Step 3: Get the cell list of NaN values: \n",
    "nanlist = f.get_nan_value(missingdf)\n",
    "\n",
    "# step 4: Impute values using imputation algorithms\n",
    "mice_imputer = IterativeImputer()\n",
    "# imputing the missing value with mice imputer\n",
    "data = mice_imputer.fit_transform(missingdf)\n",
    "missingdf = pd.DataFrame(data)\n",
    "print(\"Missing df imputed with Mice is:\")\n",
    "print(missingdf)\n",
    "\n",
    "# Step 5: Capture actual and pred values\n",
    "actual_value = f.get_value(nanlist,originaldf)\n",
    "pred_value = f.get_value(nanlist,missingdf)\n",
    "\n",
    "# Step 6: Display the error\n",
    "avg_abs_error = f.get_absolute_error(actual_value,pred_value)\n",
    "print(f\"Average Absolute Error using Mice is {avg_abs_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Mean[Sum of all non nan data/len(row)] and Field mean[Sum of all non Nan data(col wise)/len(col)]\n",
    "Code for the same is written in the class Func and function name is replace_nan_with_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meandf:\n",
      "     2017    2018   2019    2020    2021    2022\n",
      "0    15.0     NaN    2.0     3.0    18.0     4.0\n",
      "1  2298.0  2239.0    NaN  2208.0  2154.0  2098.0\n",
      "2     9.0     NaN    1.0    10.0     2.0    13.0\n",
      "3   338.0   360.0  337.0     NaN   298.0   289.0\n",
      "4   323.0   314.0  250.0   305.0   302.0     NaN\n",
      "5    40.0    43.0   37.0     NaN    44.0    39.0\n",
      "6    15.0    22.0   28.0    70.0     NaN   114.0\n",
      "7     NaN    35.0  142.0   189.0   252.0   266.0\n",
      "8    32.0    40.0   64.0     NaN    34.0    60.0\n",
      "9    20.0     NaN   35.0    17.0    30.0    32.0\n",
      "Average Absolute Error using Mean is 28.0\n",
      "Field Mean df\n",
      "          2017         2018        2019         2020         2021         2022\n",
      "0    15.000000   436.142857    2.000000     3.000000    18.000000     4.000000\n",
      "1  2298.000000  2239.000000   99.555556  2208.000000  2154.000000  2098.000000\n",
      "2     9.000000   436.142857    1.000000    10.000000     2.000000    13.000000\n",
      "3   338.000000   360.000000  337.000000   400.285714   298.000000   289.000000\n",
      "4   323.000000   314.000000  250.000000   305.000000   302.000000   323.888889\n",
      "5    40.000000    43.000000   37.000000   400.285714    44.000000    39.000000\n",
      "6    15.000000    22.000000   28.000000    70.000000   348.222222   114.000000\n",
      "7   343.333333    35.000000  142.000000   189.000000   252.000000   266.000000\n",
      "8    32.000000    40.000000   64.000000   400.285714    34.000000    60.000000\n",
      "9    20.000000   436.142857   35.000000    17.000000    30.000000    32.000000\n",
      "Average Absolute Error using Field Mean is 474.0\n"
     ]
    }
   ],
   "source": [
    "originaldf = f.get_df(rf'{original_path}')\n",
    "\n",
    "\n",
    "# Step 2: Capture Missing CSV\n",
    "missingdf = f.get_df(rf'{missing_path}')\n",
    "\n",
    "# Step 3: Get the cell list of NaN values\n",
    "nanlist = f.get_nan_value(missingdf)\n",
    "\n",
    "# step 4: Find mean\n",
    "missingdf_mean = missingdf.apply(f.replace_nan_with_mean, axis=1)\n",
    "print(\"Meandf:\")\n",
    "print(missingdf)\n",
    "# Step 5: Capture actual and pred values\n",
    "actual_value = f.get_value(nanlist,originaldf)\n",
    "pred_value = f.get_value(nanlist,missingdf_mean)\n",
    "\n",
    "# Step 6: Display the error\n",
    "avg_abs_error = f.get_absolute_error(actual_value,pred_value)\n",
    "print(f\"Average Absolute Error using Mean is {avg_abs_error}\")\n",
    "\n",
    "# step 7: Find mean\n",
    "missingdf_fmean = missingdf.apply(f.replace_nan_with_mean, axis=0)\n",
    "print(\"Field Mean df\")\n",
    "print(missingdf_fmean)\n",
    "# Step 8: Capture actual and pred values\n",
    "actual_value_new = f.get_value(nanlist,originaldf)\n",
    "pred_value_new = f.get_value(nanlist,missingdf_fmean)\n",
    "#(actual_value_new,pred_value_new)\n",
    "# Step 9: Display the error\n",
    "avg_abs_error = f.get_absolute_error(actual_value_new,pred_value_new)\n",
    "print(f\"Average Absolute Error using Field Mean is {avg_abs_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median and Field Median\n",
    "Code for the same is written in the class Func and function name is replace_nan_with_median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediandf\n",
      "     2017    2018    2019    2020    2021    2022\n",
      "0    15.0     4.0     2.0     3.0    18.0     4.0\n",
      "1  2298.0  2239.0  2208.0  2208.0  2154.0  2098.0\n",
      "2     9.0     9.0     1.0    10.0     2.0    13.0\n",
      "3   338.0   360.0   337.0   337.0   298.0   289.0\n",
      "4   323.0   314.0   250.0   305.0   302.0   305.0\n",
      "5    40.0    43.0    37.0    40.0    44.0    39.0\n",
      "6    15.0    22.0    28.0    70.0    28.0   114.0\n",
      "7   189.0    35.0   142.0   189.0   252.0   266.0\n",
      "8    32.0    40.0    64.0    40.0    34.0    60.0\n",
      "9    20.0    30.0    35.0    17.0    30.0    32.0\n",
      "Average Absolute Error using Median is 34.0\n",
      "Field Median df\n",
      "     2017    2018   2019    2020    2021    2022\n",
      "0    15.0    43.0    2.0     3.0    18.0     4.0\n",
      "1  2298.0  2239.0   37.0  2208.0  2154.0  2098.0\n",
      "2     9.0    43.0    1.0    10.0     2.0    13.0\n",
      "3   338.0   360.0  337.0    70.0   298.0   289.0\n",
      "4   323.0   314.0  250.0   305.0   302.0    60.0\n",
      "5    40.0    43.0   37.0    70.0    44.0    39.0\n",
      "6    15.0    22.0   28.0    70.0    44.0   114.0\n",
      "7    32.0    35.0  142.0   189.0   252.0   266.0\n",
      "8    32.0    40.0   64.0    70.0    34.0    60.0\n",
      "9    20.0    43.0   35.0    17.0    30.0    32.0\n",
      "Average Absolute Error using Field Median is 283.0\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Get the cell list of NaN values as Step 1 and 2 will be same \n",
    "nanlist = f.get_nan_value(missingdf)\n",
    "\n",
    "\n",
    "# step 4: Find mean\n",
    "missingdf_med = missingdf.apply(f.replace_nan_with_median, axis=1)\n",
    "print(\"Mediandf\")\n",
    "print(missingdf_med)\n",
    "# Step 5: Capture actual and pred values\n",
    "actual_value = f.get_value(nanlist,originaldf)\n",
    "pred_value = f.get_value(nanlist,missingdf_med)\n",
    "\n",
    "# Step 6: Display the error\n",
    "avg_abs_error = f.get_absolute_error(actual_value,pred_value)\n",
    "print(f\"Average Absolute Error using Median is {avg_abs_error}\")\n",
    "\n",
    "# step 7: Find field mean\n",
    "missingdf_fmed = missingdf.apply(f.replace_nan_with_median, axis=0)\n",
    "print(\"Field Median df\")\n",
    "print(missingdf_fmed)\n",
    "\n",
    "# Step 8: Capture actual and pred values\n",
    "actual_value_field = f.get_value(nanlist,originaldf)\n",
    "pred_value_field = f.get_value(nanlist,missingdf_fmed)\n",
    "\n",
    "# Step 9: Display the error for Field Median\n",
    "avg_abs_error = f.get_absolute_error(actual_value_field,pred_value_field)\n",
    "print(f\"Average Absolute Error using Field Median is {avg_abs_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Gradient obtained by averaging on the preceding and succeeding elements for the faculty member \n",
    "Code for the same is written in the class Func and function name is get_local_gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocalGradientdf\n",
      "     2017    2018    2019    2020    2021    2022\n",
      "0    15.0     8.5     2.0     3.0    18.0     4.0\n",
      "1  2298.0  2239.0  2223.5  2208.0  2154.0  2098.0\n",
      "2     9.0     5.0     1.0    10.0     2.0    13.0\n",
      "3   338.0   360.0   337.0   317.5   298.0   289.0\n",
      "4   323.0   314.0   250.0   305.0   302.0   299.0\n",
      "5    40.0    43.0    37.0    40.5    44.0    39.0\n",
      "6    15.0    22.0    28.0    70.0    92.0   114.0\n",
      "7   -72.0    35.0   142.0   189.0   252.0   266.0\n",
      "8    32.0    40.0    64.0    49.0    34.0    60.0\n",
      "9    20.0    27.5    35.0    17.0    30.0    32.0\n",
      "Average Absolute Error using LocalGradient is 19.0\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Get the cell list of NaN values\n",
    "nanlist = f.get_nan_value(missingdf)\n",
    "\n",
    "# step 4: Impute values using LocalGradient\n",
    "\n",
    "missingdfgrad = f.get_local_gradient(missingdf)\n",
    "print(\"LocalGradientdf\")\n",
    "print(missingdfgrad)\n",
    "\n",
    "# Step 5: Capture actual and pred values\n",
    "actual_value = f.get_value(nanlist,originaldf)\n",
    "pred_value = f.get_value(nanlist,missingdfgrad)\n",
    "\n",
    "# Step 6: Display the error\n",
    "avg_abs_error = f.get_absolute_error(actual_value,pred_value)\n",
    "print(f\"Average Absolute Error using LocalGradient is {avg_abs_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearest Neighbour(L1[distance based on difference between Data points] and L2[Euclidean Distance])\n",
    "Code for the same is written in the class Func and function name is get_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbour based on data point difference:\n",
      "     2017    2018   2019    2020    2021    2022\n",
      "0    15.0    43.0    2.0     3.0    18.0     4.0\n",
      "1  2298.0  2239.0  337.0  2208.0  2154.0  2098.0\n",
      "2     9.0    43.0    1.0    10.0     2.0    13.0\n",
      "3   338.0   360.0  337.0   305.0   298.0   289.0\n",
      "4   323.0   314.0  250.0   305.0   302.0   289.0\n",
      "5    40.0    43.0   37.0    17.0    44.0    39.0\n",
      "6    15.0    22.0   28.0    70.0    34.0   114.0\n",
      "7    15.0    35.0  142.0   189.0   252.0   266.0\n",
      "8    32.0    40.0   64.0    17.0    34.0    60.0\n",
      "9    20.0    43.0   35.0    17.0    30.0    32.0\n",
      "Average Absolute Error using NearestNeighbourL1 is 211.0\n",
      "Nearest Neighbour based on Euclidean data point difference:\n",
      "     2017    2018   2019    2020    2021    2022\n",
      "0    15.0    43.0    2.0     3.0    18.0     4.0\n",
      "1  2298.0  2239.0  337.0  2208.0  2154.0  2098.0\n",
      "2     9.0    43.0    1.0    10.0     2.0    13.0\n",
      "3   338.0   360.0  337.0   305.0   298.0   289.0\n",
      "4   323.0   314.0  250.0   305.0   302.0   289.0\n",
      "5    40.0    43.0   37.0    17.0    44.0    39.0\n",
      "6    15.0    22.0   28.0    70.0    34.0   114.0\n",
      "7    15.0    35.0  142.0   189.0   252.0   266.0\n",
      "8    32.0    40.0   64.0    17.0    34.0    60.0\n",
      "9    20.0    43.0   35.0    17.0    30.0    32.0\n",
      "Average Absolute Error using NearestNeighbourL2 is 211.0\n"
     ]
    }
   ],
   "source": [
    "originaldf = f.get_df(rf'{original_path}')\n",
    "#print(originaldf)\n",
    "\n",
    "# Step 2: Capture Missing CSV\n",
    "missingdf = f.get_df(rf'{missing_path}')\n",
    "\n",
    "# Step 3: Get the cell list of NaN values\n",
    "nanlist = f.get_nan_value(missingdf)\n",
    "\n",
    "# step 4: Impute values using NN1\n",
    "\n",
    "missingdfl1 = f.get_nn(missingdf,\"l1\")\n",
    "print(\"Nearest Neighbour based on data point difference:\")\n",
    "print(missingdfl1)\n",
    "# Step 5: Capture actual and pred values\n",
    "actual_value = f.get_value(nanlist,originaldf)\n",
    "pred_value = f.get_value(nanlist,missingdfl1)\n",
    "\n",
    "# Step 6: Display the error\n",
    "avg_abs_error = f.get_absolute_error(actual_value,pred_value)\n",
    "print(f\"Average Absolute Error using NearestNeighbourL1 is {avg_abs_error}\")\n",
    "\n",
    "# step 7: Impute values using NN2\n",
    "\n",
    "missingdfl2 = f.get_nn(missingdf,\"l2\")\n",
    "print(\"Nearest Neighbour based on Euclidean data point difference:\")\n",
    "print(missingdfl2)\n",
    "# Step 8: Capture actual and pred values\n",
    "actual_value = f.get_value(nanlist,originaldf)\n",
    "pred_value = f.get_value(nanlist,missingdfl2)\n",
    "\n",
    "# Step 9: Display the error\n",
    "avg_abs_error = f.get_absolute_error(actual_value,pred_value)\n",
    "print(f\"Average Absolute Error using NearestNeighbourL2 is {avg_abs_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [],
   "source": [
    "Q3] Comparison of different approaches:\n",
    "---------------------------------------------------------\n",
    "\n",
    "From the above code comparison of Average Absolute Error is as follows :\n",
    "\tMice\tMean\tFieldMean\tMedian\tFieldMedian\tLocalGradient\tNearest Neighbour L1\tNearest Neighbour L2\n",
    "    26\t\t28\t\t474         34\t\t\t283      19             211                     211\n",
    "\n",
    "    Local Gradient provides the least Average Absolute Error as noise was added to the citations distributed yearwise for each faculty member, by \n",
    "    obtaining local Gradient based on averaging the previous and following year citations value, the average obtained is closer to the real value.\n",
    "    The csv also follows a specific pattern of adding noise based on +10 or -10  and hence can also be approximated well by local relationships.\n",
    "\n",
    "    Generally, median performs better on outliers, however we can see that data is skewed towards the right, hence the median is greater than mean.\n",
    "\n",
    "    For FieldMean , the error is maximum as citations might vary for every faculty member yearwise as there is no relationship/pattern between the year \n",
    "    and the faculty member and computing the average on different varying values might lead to incorrect imputated values leading to incorrect results.\n",
    "\n",
    "    Nearest Neighbour doesnt reduce the error as although the distance might be lesser between the citations for the faculty member,\n",
    "    however the citation might vary for each faculty member."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
